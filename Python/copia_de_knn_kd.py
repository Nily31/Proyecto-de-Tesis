# -*- coding: utf-8 -*-
"""Copia de KNN-KD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pbk3cTKR9iKG31vQ923y-qgBUft8dJpO

# **Traer archivos a Colab de forma local**
"""

from google.colab import files
uploaded = files.upload()

"""# **Importar Librerías**"""

# Commented out IPython magic to ensure Python compatibility.
#Librería para manipulación y análisis de datos.
import pandas as pd  
#Librería de funciones matemáticas de alto nivel para operar con vectores y matrices.
import numpy as np    
#Librería para la generación de gráficos a partir de datos contenidos en listas o arrays.  
import matplotlib.pyplot as plt    
#mapa de colores generado a partir de una lista de colores.
from matplotlib.colors import ListedColormap  
#Librería de nivel superior a Matplotlib que permite generar fácilmente elegantes gráficos. 
import seaborn as sb      

#dibuja imágenes estáticas en el cuaderno.
# %matplotlib inline
#Esto hace que el ancho de la figura sea de 16 de ancho y su altura de 14 pulgadas.
plt.rcParams['figure.figsize'] = (16, 14) 
plt.style.use('ggplot')  #Para crear gráficos declarativamente.
 
#Selección deL modelo, nos permite dividir un dataset en dos bloques (entrenamiento y test del modelo).
from sklearn.model_selection import train_test_split  
#Clasificador que implementa el voto k-vecinos más cercanos.
from sklearn.neighbors import KNeighborsClassifier 
#Crea un informe de texto que muestra las principales métricas de clasificación.
from sklearn.metrics import classification_report
#Calcula la matriz de confusión para evaluar la precisión de una clasificación dentro del modelo.  
from sklearn.metrics import confusion_matrix  
#Estandarizar las características eliminando la media y escalando a la varianza de la unidad. 
from sklearn.preprocessing import StandardScaler

"""# **Cargamos el dataset (archivo.csv)**"""

dataframe = pd.read_csv('MasDatosNu.csv',sep=';', index_col=0) #Leer el archivo de datos con encabezado y separados por punto y comas (csv) en DataFrame.
dataframe.head(10) #Esta función devuelve las primeras 10 filas del dataset.

"""# **Resumen estadístico de los datos**"""

dataframe.info() #visualizar detalles estadísticos.

"""# **Visualización de los datos**"""

dataframe.hist(color = 'orange') #Trazar histogramas
plt.show() #función para mostrar los histogramas.

print(dataframe.groupby('classification').size()) #Dividimos los datos en grupos aplicando algunas condiciones en los conjuntos de datos.

sb.factorplot('classification',data=dataframe,kind="violin",palette="Set2") #Graficamos la variable dependiente.

"""# **Preparamos las entradas**"""

#La X representara nuestras columnas independientes.
X = dataframe[['age','bp', 'sg','al','su','rbc','pc','pcc','ba','bgr','bu','sc','sod','pot','hemo','pcv','wc','rc','htn','dm','cad','appet','pe','ane']].values
y = dataframe['classification'].values  #La Y representa nuestra columna dependiente.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) #Decidimos el tamaño de los datos que se deben dividir como conjunto de datos de prueba

#Estandarizar las variables
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""# **Elegir valor K**

**Comparación de la tasa de error con el valor K**
"""

error = []

# Error de cálculo para valores de K entre 1 y 40
for i in range(1, 40):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    pred_i = knn.predict(X_test)
    error.append(np.mean(pred_i != y_test))

plt.figure(figsize=(12, 6))
plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',
         markerfacecolor='blue', markersize=10)
plt.title('Error Rate K Value')
plt.xlabel('K Value')
plt.ylabel('Mean Error')

"""# **Crear el modelo k-Nearest Neighbor con Scikit Learn**

**1. Entrenar el modelo**
"""

#Inicializamos el clasificador y le asignamos el valor de k (puntos vecinos)
n_neighbors = 21
knn = KNeighborsClassifier(n_neighbors)
knn.fit(X_train, y_train) #Entrenamos el modelo
print('Accuracy of K-NN classifier on training set: {:.2f}'
     .format(knn.score(X_train, y_train)))
print('Accuracy of K-NN classifier on test set: {:.2f}'
     .format(knn.score(X_test, y_test)))

"""**2. Predicciones en el modelo**"""

pred = knn.predict(X_test) #Hacer predicciones sobre nuestros datos de prueba

"""# **Matriz de Confusión y Reporte de métricas**"""

print('Matriz de Confusión')
print(confusion_matrix(y_test, pred)) #imprimimos la matriz de confusión
print('\n')
print('Reporte de Métricas')
print(classification_report(y_test, pred)) #generamos el reporte de métricas de evaluación