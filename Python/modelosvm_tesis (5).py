# -*- coding: utf-8 -*-
"""ModeloSVM-TESIS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QXYOpPrlmRwhDleq0zm4Ru5e3sM_GZ8h

permite importar a google colab datasets
"""

from google.colab  import files

"""seleccionamos el Dataset desde nuestros documentos"""

files.upload()

"""importamos pandas para que nos permite leer nuestro archivo CSV"""

import pandas as pd

"""almacenar la informacion contenida en el datset en la variable datos"""

datos= pd.read_csv('MasDatosNu.csv',sep=';')

"""ver el nombre de las columnas del dataset"""

datos.head()

"""eliminar la columna id del datsaet ya que cuando se convierten en formato pandas ya incluye un numeración"""

datos= datos.drop('id',axis=1)

"""comprabamos que se elimino la columna id"""

datos.head()

"""Análizamos los datos que tenemos disponibles"""

print(datos.info())

"""podemos observar los datos estadísticos del dataset"""

print(datos.describe())

"""cantidad de pacientes sanos y enfermos"""

print (datos.groupby('classification').size())

"""Grafiquemos algunos valores del dataset original

veamos los datos de manera visual, para ello importamos la librería de matplotlib y procedamos a graficar el dataset.
"""

from matplotlib import pyplot as plt

# Gráfico de pastel de pacientes
plot = datos['classification'].value_counts().plot(kind='pie', autopct='%.2f', 
                                            figsize=(6, 6),
                                            title='Pacientes')

# Gráfico de barras de pacientes segun el nivel de azucar
plot = pd.crosstab(index=datos['classification'],
            columns=datos['su']).apply(lambda r: r/r.sum() *100,
                                              axis=1).plot(kind='bar')

"""importamos la libreria que se encarga de dividir en X y Y los datos"""

import numpy as np

"""división de la información: en X estara conformado por 24 caracteristicas (predictoras) que nos permitan realizan la clasificación (ecepto el id, y la columna classification)"""

X= np.array(datos.drop(['classification'],1))

"""en y contendran la columna "classification" con la variable respuesta"""

y= np.array(datos['classification'])

"""importando la libre sklearn.model para asiganr el conjunto de entrenamiento y prueba"""

from sklearn.model_selection import train_test_split

"""separamos los datos de entrenamiento y prueba utilizando la instrucción train_test_split. y asigamos el 30% de la informacion para realizar las pruebas la instruccion random_state es para que cada vez que se ejecute los valores no cambien"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

"""comprobar cuantos datos se asignaron para el entrenamiento y las pruebas"""

print('Son {} datos para entrenamiento y {} datos para prueba'.format(X_train.shape[0], X_test.shape[0]))

"""representacion grafica de datos disponibles : se observa que no son linealmente separables"""

my_plot = datos.plot("sg","al",kind="scatter" ,
c= 'red')
plt.show()

my_plot = datos.plot("hemo","su",kind="scatter",
 c='orange'                    )
plt.show()

my_plot = datos.plot("bu","age",kind="scatter",
c='green')
plt.show()

"""importamos el metodo GridSerchCVV de la libreria scikit-learn que permite evaluar y seleccionar de forma sistemática los parámetros de un modelo

Metodo Para comprobar la eleccion del Kernel y el parametro C

importamos el modulo de support vector machine clasificación
"""

from sklearn.svm import SVC

from sklearn.model_selection import GridSearchCV

# creación del modelo
Modelo = SVC(random_state=1982)

parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},
              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]
grid_search = GridSearchCV(estimator = Modelo,
                           param_grid = parameters,
                           scoring = 'accuracy',
                           cv = 10,
                           n_jobs = -1)
grid_search = grid_search.fit(X_train, y_train)

"""Calculamos la exactitud del mejor modelo"""

accuracy = grid_search.best_score_

accuracy

"""parametros del mejor modelo"""

grid_search.best_params_

"""creamos el modelo support vector machine"""

algoritmo = grid_search.best_estimator_

"""entrenamos el modelo con las variables previamente creadas y establecidas como train"""

algoritmo.fit(X_train,y_train)

# Se construye la recta que separa las clases
w = algoritmo.coef_[0]
a = -w[0] / w[1]
xx = np.linspace(-5, 5)
yy = a * xx - (algoritmo.intercept_[0]) / w[1]

# support vectors
b = algoritmo.support_vectors_[0]
yy_down = a * xx + (b[1] - a * b[0])
b = algoritmo.support_vectors_[-1]
yy_up = a * xx + (b[1] - a * b[0])

#Gráfica
plt.plot(xx, yy, 'k-')
plt.plot(xx, yy_down, 'k--')
plt.plot(xx, yy_up, 'k--')

plt.scatter(algoritmo.support_vectors_[:, 0], algoritmo.support_vectors_[:, 1],
 s=80, facecolors='none')
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)

plt.title('Recta separadora')
plt.axis('tight')
plt.show()

"""precisión en el entrenamiento"""

print('exactitud Máquinas de Vectores de Soporte en el entrenamiento : {}'.format(algoritmo.score(X_train,y_train)))

"""luego de entrenarlo realizaremos una predicción con las variables de prueba"""

y_pred= algoritmo.predict(X_test)

"""observamos cuales fueron las predicciones"""

print(y_pred)

"""importamos la función confusion matrix para observar el nivel de acierto en las predicciones

Métricas de Evaluación para el modelo de la clasificación SVM
"""

from sklearn.metrics import confusion_matrix

"""la matriz de confusión recibe como parametros ypred que contiene las predicciones y y_test que es la informacion real"""

matriz= confusion_matrix(y_test,y_pred)

"""imprimimos la matriz para observar resultados"""

print(matriz)

"""importamos de el metodo acurracy_score de la libreria sklearn.metrics para medir la exactitud en las pruebas"""

from sklearn.metrics import accuracy_score

"""para medir la exactitud de las pruebas se basa en los resultados obtenidos en la matriz de confusión"""

exactitud = accuracy_score(y_test,y_pred)
print(exactitud)

"""importamos el metodo precision_score de la libreria sklearn.metrics para medir la presición en las pruebas"""

from sklearn.metrics import precision_score

precision = precision_score(y_test,y_pred)
print(precision)

"""importamos el metodo recall_score de la libreria sklearn.metrics para medir la sensibilidad en las pruebas"""

from sklearn.metrics import recall_score

sensibilidad = recall_score(y_test, y_pred)
print(sensibilidad)

"""importamos el metodo f1_score de la libreria sklearn.metrics  
El puntaje F1 es la medida armónica de la memoria y la precisión, con una puntuación más alta como mejor modelo.
"""

from sklearn.metrics import f1_score

puntaje= f1_score(y_test,y_pred)
print(puntaje)